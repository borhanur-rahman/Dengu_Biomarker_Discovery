{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPyZu89orT4medqDZOX+awl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/borhanur-rahman/Dengu_Biomarker_Discovery/blob/main/Dengu_Biomarker_Discovery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cMHjMtmGgDc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "1dc668f5-60e8-424b-904e-e258762f01b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: GEOparse in /usr/local/lib/python3.12/dist-packages (2.0.4)\n",
            "Requirement already satisfied: gseapy in /usr/local/lib/python3.12/dist-packages (1.1.11)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.2.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.12/dist-packages (0.14.6)\n",
            "Requirement already satisfied: rpy2 in /usr/local/lib/python3.12/dist-packages (3.5.17)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (3.6.1)\n",
            "Requirement already satisfied: py4cytoscape in /usr/local/lib/python3.12/dist-packages (1.13.0)\n",
            "Requirement already satisfied: biopython in /usr/local/lib/python3.12/dist-packages (1.86)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.12/dist-packages (from GEOparse) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.17 in /usr/local/lib/python3.12/dist-packages (from GEOparse) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.12/dist-packages (from GEOparse) (4.67.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from gseapy) (1.16.3)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.12/dist-packages (from gseapy) (3.10.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras) (3.15.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras) (0.18.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras) (0.5.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras) (26.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.12.19)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.78.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels) (1.0.2)\n",
            "Requirement already satisfied: cffi>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from rpy2) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from rpy2) (3.1.6)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.12/dist-packages (from rpy2) (5.3.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2026.1.4)\n",
            "Requirement already satisfied: igraph in /usr/local/lib/python3.12/dist-packages (from py4cytoscape) (1.0.0)\n",
            "Requirement already satisfied: colorbrewer in /usr/local/lib/python3.12/dist-packages (from py4cytoscape) (0.3)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.12/dist-packages (from py4cytoscape) (5.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from py4cytoscape) (4.4.2)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.12/dist-packages (from py4cytoscape) (2.2.1)\n",
            "Requirement already satisfied: colour in /usr/local/lib/python3.12/dist-packages (from py4cytoscape) (0.1.5)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.46.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.15.1->rpy2) (3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2->gseapy) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2->gseapy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2->gseapy) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2->gseapy) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2->gseapy) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2->gseapy) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2->gseapy) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.17->GEOparse) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.17->GEOparse) (2025.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.5)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.12/dist-packages (from igraph->py4cytoscape) (1.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->rpy2) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Mount Drive & Installs\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install required packages (gseapy works fine)\n",
        "!pip install GEOparse gseapy scikit-learn xgboost keras tensorflow statsmodels rpy2 requests networkx py4cytoscape biopython\n",
        "\n",
        "# No boruta_py → we use RF importance instead (paper's FCBF equivalent)\n",
        "# For enrichment (like CKD notebook)\n",
        "import gseapy as gp\n",
        "\n",
        "# Imports (full set for pipeline)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import mannwhitneyu\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "import GEOparse\n",
        "from Bio import Entrez\n",
        "import requests\n",
        "import networkx as nx\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score, classification_report, roc_curve\n",
        "from xgboost import XGBClassifier\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "Entrez.email = \"borhanurrahman1@gmail.com\"  # Required for NCBI (change to yours)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# 2️⃣ Load Dengue Expression Matrix & Metadata from GEO\n",
        "# ------------------------------\n",
        "\n",
        "import GEOparse\n",
        "import pandas as pd\n",
        "\n",
        "# Target dataset from your slides: GSE51808 (PBMCs mild vs severe dengue)\n",
        "gse_id = 'GSE51808'\n",
        "\n",
        "print(f\"Downloading and parsing {gse_id}...\")\n",
        "gse = GEOparse.get_GEO(geo=gse_id, destdir=\"./\")\n",
        "\n",
        "# Expression matrix: genes as rows, samples as columns\n",
        "# 'VALUE' is usually the normalized/log-transformed intensity\n",
        "expr = gse.pivot_samples('VALUE')\n",
        "\n",
        "print(\"\\nExpression matrix shape (genes × samples):\", expr.shape)\n",
        "print(\"\\nFirst 5 genes and 5 samples:\")\n",
        "display(expr.iloc[:5, :5])\n",
        "\n",
        "# Save expression to Drive (reuse later)\n",
        "expr.to_csv('/content/drive/MyDrive/BioResearch/dengue_GSE51808_expression.csv')\n",
        "print(\"Expression matrix saved to Drive.\")\n",
        "\n",
        "# ────────────────────────────────────────────────\n",
        "# Inspect metadata columns (very important!)\n",
        "# ────────────────────────────────────────────────\n",
        "pheno = gse.phenotype_data.copy()\n",
        "\n",
        "print(\"\\nAll available metadata columns:\")\n",
        "print(pheno.columns.tolist())\n",
        "\n",
        "print(\"\\nFirst few rows of metadata:\")\n",
        "display(pheno.head())\n",
        "\n",
        "# Look for columns that likely contain disease state\n",
        "# Common candidates in GSE51808:\n",
        "possible_columns = [col for col in pheno.columns if 'characteristic' in col.lower() or 'source' in col.lower() or 'disease' in col.lower() or 'status' in col.lower()]\n",
        "\n",
        "print(\"\\nColumns that probably contain severity info:\")\n",
        "print(possible_columns)\n",
        "\n",
        "# ────────────────────────────────────────────────\n",
        "# Create 'group' column – adjust based on print output above\n",
        "# ────────────────────────────────────────────────\n",
        "# Example: in GSE51808, severity is often in 'source_name_ch1' or 'characteristics_ch1'\n",
        "# Run this AFTER you see the print output and choose the correct column\n",
        "\n",
        "# Option 1: if severity is in 'source_name_ch1'\n",
        "if 'source_name_ch1' in pheno.columns:\n",
        "    pheno['group'] = pheno['source_name_ch1'].apply(\n",
        "        lambda x: 'severe' if 'hemorrhagic' in str(x).lower() or 'severe' in str(x).lower() else 'non-severe'\n",
        "    )\n",
        "\n",
        "# Option 2: if severity is in 'characteristics_ch1' or similar (uncomment if needed)\n",
        "# elif 'characteristics_ch1' in pheno.columns:\n",
        "#     pheno['group'] = pheno['characteristics_ch1'].apply(\n",
        "#         lambda x: 'severe' if 'hemorrhagic' in str(x).lower() or 'severe' in str(x).lower() else 'non-severe'\n",
        "#     )\n",
        "\n",
        "# Fallback: print unique values to help choose\n",
        "print(\"\\nUnique values in source_name_ch1 (if exists):\")\n",
        "if 'source_name_ch1' in pheno.columns:\n",
        "    print(pheno['source_name_ch1'].unique())\n",
        "\n",
        "# Show final group distribution\n",
        "print(\"\\nFinal group distribution (after assignment):\")\n",
        "print(pheno['group'].value_counts())\n",
        "\n",
        "# Save metadata\n",
        "pheno.to_csv('/content/drive/MyDrive/BioResearch/dengue_GSE51808_metadata.csv')\n",
        "print(\"Metadata saved to Drive.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Bh6mN2CRc8qx",
        "outputId": "b452bf9a-35be-4fd4-cd82-87f19ff8b23d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26-Feb-2026 06:34:44 DEBUG utils - Directory ./ already exists. Skipping.\n",
            "DEBUG:GEOparse:Directory ./ already exists. Skipping.\n",
            "26-Feb-2026 06:34:44 INFO GEOparse - File already exist: using local version.\n",
            "INFO:GEOparse:File already exist: using local version.\n",
            "26-Feb-2026 06:34:44 INFO GEOparse - Parsing ./GSE51808_family.soft.gz: \n",
            "INFO:GEOparse:Parsing ./GSE51808_family.soft.gz: \n",
            "26-Feb-2026 06:34:44 DEBUG GEOparse - DATABASE: GeoMiame\n",
            "DEBUG:GEOparse:DATABASE: GeoMiame\n",
            "26-Feb-2026 06:34:44 DEBUG GEOparse - SERIES: GSE51808\n",
            "DEBUG:GEOparse:SERIES: GSE51808\n",
            "26-Feb-2026 06:34:44 DEBUG GEOparse - PLATFORM: GPL13158\n",
            "DEBUG:GEOparse:PLATFORM: GPL13158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and parsing GSE51808...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/GEOparse/GEOparse.py:401: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return read_csv(StringIO(data), index_col=None, sep=\"\\t\")\n",
            "26-Feb-2026 06:34:48 DEBUG GEOparse - SAMPLE: GSM1253028\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253028\n",
            "26-Feb-2026 06:34:48 DEBUG GEOparse - SAMPLE: GSM1253029\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253029\n",
            "26-Feb-2026 06:34:48 DEBUG GEOparse - SAMPLE: GSM1253030\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253030\n",
            "26-Feb-2026 06:34:48 DEBUG GEOparse - SAMPLE: GSM1253031\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253031\n",
            "26-Feb-2026 06:34:49 DEBUG GEOparse - SAMPLE: GSM1253032\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253032\n",
            "26-Feb-2026 06:34:49 DEBUG GEOparse - SAMPLE: GSM1253033\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253033\n",
            "26-Feb-2026 06:34:49 DEBUG GEOparse - SAMPLE: GSM1253034\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253034\n",
            "26-Feb-2026 06:34:50 DEBUG GEOparse - SAMPLE: GSM1253035\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253035\n",
            "26-Feb-2026 06:34:50 DEBUG GEOparse - SAMPLE: GSM1253036\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253036\n",
            "26-Feb-2026 06:34:50 DEBUG GEOparse - SAMPLE: GSM1253037\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253037\n",
            "26-Feb-2026 06:34:51 DEBUG GEOparse - SAMPLE: GSM1253038\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253038\n",
            "26-Feb-2026 06:34:51 DEBUG GEOparse - SAMPLE: GSM1253039\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253039\n",
            "26-Feb-2026 06:34:51 DEBUG GEOparse - SAMPLE: GSM1253040\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253040\n",
            "26-Feb-2026 06:34:51 DEBUG GEOparse - SAMPLE: GSM1253041\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253041\n",
            "26-Feb-2026 06:34:51 DEBUG GEOparse - SAMPLE: GSM1253042\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253042\n",
            "26-Feb-2026 06:34:52 DEBUG GEOparse - SAMPLE: GSM1253043\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253043\n",
            "26-Feb-2026 06:34:52 DEBUG GEOparse - SAMPLE: GSM1253044\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253044\n",
            "26-Feb-2026 06:34:52 DEBUG GEOparse - SAMPLE: GSM1253045\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253045\n",
            "26-Feb-2026 06:34:52 DEBUG GEOparse - SAMPLE: GSM1253046\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253046\n",
            "26-Feb-2026 06:34:53 DEBUG GEOparse - SAMPLE: GSM1253047\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253047\n",
            "26-Feb-2026 06:34:53 DEBUG GEOparse - SAMPLE: GSM1253048\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253048\n",
            "26-Feb-2026 06:34:53 DEBUG GEOparse - SAMPLE: GSM1253049\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253049\n",
            "26-Feb-2026 06:34:53 DEBUG GEOparse - SAMPLE: GSM1253050\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253050\n",
            "26-Feb-2026 06:34:53 DEBUG GEOparse - SAMPLE: GSM1253051\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253051\n",
            "26-Feb-2026 06:34:54 DEBUG GEOparse - SAMPLE: GSM1253052\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253052\n",
            "26-Feb-2026 06:34:54 DEBUG GEOparse - SAMPLE: GSM1253053\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253053\n",
            "26-Feb-2026 06:34:54 DEBUG GEOparse - SAMPLE: GSM1253054\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253054\n",
            "26-Feb-2026 06:34:54 DEBUG GEOparse - SAMPLE: GSM1253055\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253055\n",
            "26-Feb-2026 06:34:55 DEBUG GEOparse - SAMPLE: GSM1253056\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253056\n",
            "26-Feb-2026 06:34:55 DEBUG GEOparse - SAMPLE: GSM1253057\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253057\n",
            "26-Feb-2026 06:34:56 DEBUG GEOparse - SAMPLE: GSM1253058\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253058\n",
            "26-Feb-2026 06:34:56 DEBUG GEOparse - SAMPLE: GSM1253059\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253059\n",
            "26-Feb-2026 06:34:57 DEBUG GEOparse - SAMPLE: GSM1253060\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253060\n",
            "26-Feb-2026 06:34:57 DEBUG GEOparse - SAMPLE: GSM1253061\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253061\n",
            "26-Feb-2026 06:34:58 DEBUG GEOparse - SAMPLE: GSM1253062\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253062\n",
            "26-Feb-2026 06:34:58 DEBUG GEOparse - SAMPLE: GSM1253063\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253063\n",
            "26-Feb-2026 06:34:59 DEBUG GEOparse - SAMPLE: GSM1253064\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253064\n",
            "26-Feb-2026 06:34:59 DEBUG GEOparse - SAMPLE: GSM1253065\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253065\n",
            "26-Feb-2026 06:35:00 DEBUG GEOparse - SAMPLE: GSM1253066\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253066\n",
            "26-Feb-2026 06:35:00 DEBUG GEOparse - SAMPLE: GSM1253067\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253067\n",
            "26-Feb-2026 06:35:00 DEBUG GEOparse - SAMPLE: GSM1253068\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253068\n",
            "26-Feb-2026 06:35:00 DEBUG GEOparse - SAMPLE: GSM1253069\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253069\n",
            "26-Feb-2026 06:35:00 DEBUG GEOparse - SAMPLE: GSM1253070\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253070\n",
            "26-Feb-2026 06:35:01 DEBUG GEOparse - SAMPLE: GSM1253071\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253071\n",
            "26-Feb-2026 06:35:01 DEBUG GEOparse - SAMPLE: GSM1253072\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253072\n",
            "26-Feb-2026 06:35:01 DEBUG GEOparse - SAMPLE: GSM1253073\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253073\n",
            "26-Feb-2026 06:35:02 DEBUG GEOparse - SAMPLE: GSM1253074\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253074\n",
            "26-Feb-2026 06:35:02 DEBUG GEOparse - SAMPLE: GSM1253075\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253075\n",
            "26-Feb-2026 06:35:02 DEBUG GEOparse - SAMPLE: GSM1253076\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253076\n",
            "26-Feb-2026 06:35:02 DEBUG GEOparse - SAMPLE: GSM1253077\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253077\n",
            "26-Feb-2026 06:35:02 DEBUG GEOparse - SAMPLE: GSM1253078\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253078\n",
            "26-Feb-2026 06:35:03 DEBUG GEOparse - SAMPLE: GSM1253079\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253079\n",
            "26-Feb-2026 06:35:03 DEBUG GEOparse - SAMPLE: GSM1253080\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253080\n",
            "26-Feb-2026 06:35:03 DEBUG GEOparse - SAMPLE: GSM1253081\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253081\n",
            "26-Feb-2026 06:35:03 DEBUG GEOparse - SAMPLE: GSM1253082\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253082\n",
            "26-Feb-2026 06:35:04 DEBUG GEOparse - SAMPLE: GSM1253083\n",
            "DEBUG:GEOparse:SAMPLE: GSM1253083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Expression matrix shape (genes × samples): (54715, 56)\n",
            "\n",
            "First 5 genes and 5 samples:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "name          GSM1253028  GSM1253029  GSM1253030  GSM1253031  GSM1253032\n",
              "ID_REF                                                                  \n",
              "1007_PM_s_at     5.97419     5.55657     6.51326     5.87408     5.36585\n",
              "1053_PM_at       7.88225     7.75510     8.42061     7.78163     6.90308\n",
              "117_PM_at       10.01840     8.97969     7.61888    10.45590    11.14070\n",
              "121_PM_at        6.24138     6.55102     5.96311     5.99571     5.51645\n",
              "1255_PM_g_at     2.92204     3.18026     2.67519     2.64095     2.76739"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3bbd3ef8-f82a-43c2-9877-c2c22ac27007\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>name</th>\n",
              "      <th>GSM1253028</th>\n",
              "      <th>GSM1253029</th>\n",
              "      <th>GSM1253030</th>\n",
              "      <th>GSM1253031</th>\n",
              "      <th>GSM1253032</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID_REF</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1007_PM_s_at</th>\n",
              "      <td>5.97419</td>\n",
              "      <td>5.55657</td>\n",
              "      <td>6.51326</td>\n",
              "      <td>5.87408</td>\n",
              "      <td>5.36585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1053_PM_at</th>\n",
              "      <td>7.88225</td>\n",
              "      <td>7.75510</td>\n",
              "      <td>8.42061</td>\n",
              "      <td>7.78163</td>\n",
              "      <td>6.90308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117_PM_at</th>\n",
              "      <td>10.01840</td>\n",
              "      <td>8.97969</td>\n",
              "      <td>7.61888</td>\n",
              "      <td>10.45590</td>\n",
              "      <td>11.14070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121_PM_at</th>\n",
              "      <td>6.24138</td>\n",
              "      <td>6.55102</td>\n",
              "      <td>5.96311</td>\n",
              "      <td>5.99571</td>\n",
              "      <td>5.51645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1255_PM_g_at</th>\n",
              "      <td>2.92204</td>\n",
              "      <td>3.18026</td>\n",
              "      <td>2.67519</td>\n",
              "      <td>2.64095</td>\n",
              "      <td>2.76739</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3bbd3ef8-f82a-43c2-9877-c2c22ac27007')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3bbd3ef8-f82a-43c2-9877-c2c22ac27007 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3bbd3ef8-f82a-43c2-9877-c2c22ac27007');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"Metadata saved to Drive\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"ID_REF\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"1053_PM_at\",\n          \"1255_PM_g_at\",\n          \"117_PM_at\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GSM1253028\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.616150181042747,\n        \"min\": 2.92204,\n        \"max\": 10.0184,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7.88225,\n          2.92204,\n          10.0184\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GSM1253029\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.2131369628357844,\n        \"min\": 3.18026,\n        \"max\": 8.97969,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7.7551,\n          3.18026,\n          8.97969\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GSM1253030\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.208821147229897,\n        \"min\": 2.67519,\n        \"max\": 8.42061,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          8.42061,\n          2.67519,\n          7.61888\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GSM1253031\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.864338659329584,\n        \"min\": 2.64095,\n        \"max\": 10.4559,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7.78163,\n          2.64095,\n          10.4559\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GSM1253032\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.072235183271294,\n        \"min\": 2.76739,\n        \"max\": 11.1407,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          6.90308,\n          2.76739,\n          11.1407\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expression matrix saved to Drive.\n",
            "\n",
            "All available metadata columns:\n",
            "['title', 'geo_accession', 'status', 'submission_date', 'last_update_date', 'type', 'channel_count', 'source_name_ch1', 'organism_ch1', 'taxid_ch1', 'characteristics_ch1.0.subject id', 'characteristics_ch1.1.infection', 'characteristics_ch1.2.status', 'characteristics_ch1.3.tissue', 'treatment_protocol_ch1', 'molecule_ch1', 'extract_protocol_ch1', 'label_ch1', 'label_protocol_ch1', 'hyb_protocol', 'scan_protocol', 'description', 'data_processing', 'platform_id', 'contact_name', 'contact_email', 'contact_phone', 'contact_laboratory', 'contact_institute', 'contact_address', 'contact_city', 'contact_state', 'contact_zip/postal_code', 'contact_country', 'supplementary_file', 'series_id', 'data_row_count']\n",
            "\n",
            "First few rows of metadata:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                          title geo_accession  \\\n",
              "GSM1253028               Dengue Fever Patient 3    GSM1253028   \n",
              "GSM1253029               Dengue Fever Patient 4    GSM1253029   \n",
              "GSM1253030               Dengue Fever Patient 6    GSM1253030   \n",
              "GSM1253031               Dengue Fever Patient 7    GSM1253031   \n",
              "GSM1253032  Dengue Hemorrhagic Fever Patient 32    GSM1253032   \n",
              "\n",
              "                           status submission_date last_update_date type  \\\n",
              "GSM1253028  Public on Jun 27 2014     Oct 28 2013      Jun 27 2014  RNA   \n",
              "GSM1253029  Public on Jun 27 2014     Oct 28 2013      Jun 27 2014  RNA   \n",
              "GSM1253030  Public on Jun 27 2014     Oct 28 2013      Jun 27 2014  RNA   \n",
              "GSM1253031  Public on Jun 27 2014     Oct 28 2013      Jun 27 2014  RNA   \n",
              "GSM1253032  Public on Jun 27 2014     Oct 28 2013      Jun 27 2014  RNA   \n",
              "\n",
              "           channel_count                                    source_name_ch1  \\\n",
              "GSM1253028             1  Whole Blood of Dengue infected patient at acut...   \n",
              "GSM1253029             1  Whole Blood of Dengue infected patient at acut...   \n",
              "GSM1253030             1  Whole Blood of Dengue infected patient at acut...   \n",
              "GSM1253031             1  Whole Blood of Dengue infected patient at acut...   \n",
              "GSM1253032             1  Whole Blood of Dengue infected patient at acut...   \n",
              "\n",
              "            organism_ch1 taxid_ch1  ... contact_laboratory  \\\n",
              "GSM1253028  Homo sapiens      9606  ...      csbiology.com   \n",
              "GSM1253029  Homo sapiens      9606  ...      csbiology.com   \n",
              "GSM1253030  Homo sapiens      9606  ...      csbiology.com   \n",
              "GSM1253031  Homo sapiens      9606  ...      csbiology.com   \n",
              "GSM1253032  Homo sapiens      9606  ...      csbiology.com   \n",
              "\n",
              "                    contact_institute  \\\n",
              "GSM1253028  Universidade de São Paulo   \n",
              "GSM1253029  Universidade de São Paulo   \n",
              "GSM1253030  Universidade de São Paulo   \n",
              "GSM1253031  Universidade de São Paulo   \n",
              "GSM1253032  Universidade de São Paulo   \n",
              "\n",
              "                                           contact_address contact_city  \\\n",
              "GSM1253028  AVENIDA PROFESSOR LINEU PRESTES, 580, Block 17    SÃO PAULO   \n",
              "GSM1253029  AVENIDA PROFESSOR LINEU PRESTES, 580, Block 17    SÃO PAULO   \n",
              "GSM1253030  AVENIDA PROFESSOR LINEU PRESTES, 580, Block 17    SÃO PAULO   \n",
              "GSM1253031  AVENIDA PROFESSOR LINEU PRESTES, 580, Block 17    SÃO PAULO   \n",
              "GSM1253032  AVENIDA PROFESSOR LINEU PRESTES, 580, Block 17    SÃO PAULO   \n",
              "\n",
              "           contact_state contact_zip/postal_code contact_country  \\\n",
              "GSM1253028     SÃO PAULO                05508000          Brazil   \n",
              "GSM1253029     SÃO PAULO                05508000          Brazil   \n",
              "GSM1253030     SÃO PAULO                05508000          Brazil   \n",
              "GSM1253031     SÃO PAULO                05508000          Brazil   \n",
              "GSM1253032     SÃO PAULO                05508000          Brazil   \n",
              "\n",
              "                                           supplementary_file series_id  \\\n",
              "GSM1253028  ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM1253...  GSE51808   \n",
              "GSM1253029  ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM1253...  GSE51808   \n",
              "GSM1253030  ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM1253...  GSE51808   \n",
              "GSM1253031  ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM1253...  GSE51808   \n",
              "GSM1253032  ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM1253...  GSE51808   \n",
              "\n",
              "           data_row_count  \n",
              "GSM1253028          54715  \n",
              "GSM1253029          54715  \n",
              "GSM1253030          54715  \n",
              "GSM1253031          54715  \n",
              "GSM1253032          54715  \n",
              "\n",
              "[5 rows x 37 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-678744bd-251a-4fe3-8a5f-dc995d085c52\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>geo_accession</th>\n",
              "      <th>status</th>\n",
              "      <th>submission_date</th>\n",
              "      <th>last_update_date</th>\n",
              "      <th>type</th>\n",
              "      <th>channel_count</th>\n",
              "      <th>source_name_ch1</th>\n",
              "      <th>organism_ch1</th>\n",
              "      <th>taxid_ch1</th>\n",
              "      <th>...</th>\n",
              "      <th>contact_laboratory</th>\n",
              "      <th>contact_institute</th>\n",
              "      <th>contact_address</th>\n",
              "      <th>contact_city</th>\n",
              "      <th>contact_state</th>\n",
              "      <th>contact_zip/postal_code</th>\n",
              "      <th>contact_country</th>\n",
              "      <th>supplementary_file</th>\n",
              "      <th>series_id</th>\n",
              "      <th>data_row_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>GSM1253028</th>\n",
              "      <td>Dengue Fever Patient 3</td>\n",
              "      <td>GSM1253028</td>\n",
              "      <td>Public on Jun 27 2014</td>\n",
              "      <td>Oct 28 2013</td>\n",
              "      <td>Jun 27 2014</td>\n",
              "      <td>RNA</td>\n",
              "      <td>1</td>\n",
              "      <td>Whole Blood of Dengue infected patient at acut...</td>\n",
              "      <td>Homo sapiens</td>\n",
              "      <td>9606</td>\n",
              "      <td>...</td>\n",
              "      <td>csbiology.com</td>\n",
              "      <td>Universidade de São Paulo</td>\n",
              "      <td>AVENIDA PROFESSOR LINEU PRESTES, 580, Block 17</td>\n",
              "      <td>SÃO PAULO</td>\n",
              "      <td>SÃO PAULO</td>\n",
              "      <td>05508000</td>\n",
              "      <td>Brazil</td>\n",
              "      <td>ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM1253...</td>\n",
              "      <td>GSE51808</td>\n",
              "      <td>54715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GSM1253029</th>\n",
              "      <td>Dengue Fever Patient 4</td>\n",
              "      <td>GSM1253029</td>\n",
              "      <td>Public on Jun 27 2014</td>\n",
              "      <td>Oct 28 2013</td>\n",
              "      <td>Jun 27 2014</td>\n",
              "      <td>RNA</td>\n",
              "      <td>1</td>\n",
              "      <td>Whole Blood of Dengue infected patient at acut...</td>\n",
              "      <td>Homo sapiens</td>\n",
              "      <td>9606</td>\n",
              "      <td>...</td>\n",
              "      <td>csbiology.com</td>\n",
              "      <td>Universidade de São Paulo</td>\n",
              "      <td>AVENIDA PROFESSOR LINEU PRESTES, 580, Block 17</td>\n",
              "      <td>SÃO PAULO</td>\n",
              "      <td>SÃO PAULO</td>\n",
              "      <td>05508000</td>\n",
              "      <td>Brazil</td>\n",
              "      <td>ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM1253...</td>\n",
              "      <td>GSE51808</td>\n",
              "      <td>54715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GSM1253030</th>\n",
              "      <td>Dengue Fever Patient 6</td>\n",
              "      <td>GSM1253030</td>\n",
              "      <td>Public on Jun 27 2014</td>\n",
              "      <td>Oct 28 2013</td>\n",
              "      <td>Jun 27 2014</td>\n",
              "      <td>RNA</td>\n",
              "      <td>1</td>\n",
              "      <td>Whole Blood of Dengue infected patient at acut...</td>\n",
              "      <td>Homo sapiens</td>\n",
              "      <td>9606</td>\n",
              "      <td>...</td>\n",
              "      <td>csbiology.com</td>\n",
              "      <td>Universidade de São Paulo</td>\n",
              "      <td>AVENIDA PROFESSOR LINEU PRESTES, 580, Block 17</td>\n",
              "      <td>SÃO PAULO</td>\n",
              "      <td>SÃO PAULO</td>\n",
              "      <td>05508000</td>\n",
              "      <td>Brazil</td>\n",
              "      <td>ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM1253...</td>\n",
              "      <td>GSE51808</td>\n",
              "      <td>54715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GSM1253031</th>\n",
              "      <td>Dengue Fever Patient 7</td>\n",
              "      <td>GSM1253031</td>\n",
              "      <td>Public on Jun 27 2014</td>\n",
              "      <td>Oct 28 2013</td>\n",
              "      <td>Jun 27 2014</td>\n",
              "      <td>RNA</td>\n",
              "      <td>1</td>\n",
              "      <td>Whole Blood of Dengue infected patient at acut...</td>\n",
              "      <td>Homo sapiens</td>\n",
              "      <td>9606</td>\n",
              "      <td>...</td>\n",
              "      <td>csbiology.com</td>\n",
              "      <td>Universidade de São Paulo</td>\n",
              "      <td>AVENIDA PROFESSOR LINEU PRESTES, 580, Block 17</td>\n",
              "      <td>SÃO PAULO</td>\n",
              "      <td>SÃO PAULO</td>\n",
              "      <td>05508000</td>\n",
              "      <td>Brazil</td>\n",
              "      <td>ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM1253...</td>\n",
              "      <td>GSE51808</td>\n",
              "      <td>54715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GSM1253032</th>\n",
              "      <td>Dengue Hemorrhagic Fever Patient 32</td>\n",
              "      <td>GSM1253032</td>\n",
              "      <td>Public on Jun 27 2014</td>\n",
              "      <td>Oct 28 2013</td>\n",
              "      <td>Jun 27 2014</td>\n",
              "      <td>RNA</td>\n",
              "      <td>1</td>\n",
              "      <td>Whole Blood of Dengue infected patient at acut...</td>\n",
              "      <td>Homo sapiens</td>\n",
              "      <td>9606</td>\n",
              "      <td>...</td>\n",
              "      <td>csbiology.com</td>\n",
              "      <td>Universidade de São Paulo</td>\n",
              "      <td>AVENIDA PROFESSOR LINEU PRESTES, 580, Block 17</td>\n",
              "      <td>SÃO PAULO</td>\n",
              "      <td>SÃO PAULO</td>\n",
              "      <td>05508000</td>\n",
              "      <td>Brazil</td>\n",
              "      <td>ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM1253...</td>\n",
              "      <td>GSE51808</td>\n",
              "      <td>54715</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 37 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-678744bd-251a-4fe3-8a5f-dc995d085c52')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-678744bd-251a-4fe3-8a5f-dc995d085c52 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-678744bd-251a-4fe3-8a5f-dc995d085c52');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Columns that probably contain severity info:\n",
            "['status', 'source_name_ch1', 'characteristics_ch1.0.subject id', 'characteristics_ch1.1.infection', 'characteristics_ch1.2.status', 'characteristics_ch1.3.tissue']\n",
            "\n",
            "Unique values in source_name_ch1 (if exists):\n",
            "['Whole Blood of Dengue infected patient at acute infection time point'\n",
            " 'Whole Blood of Dengue infected patient at convalescent time point'\n",
            " 'Whole Blood of healthy control']\n",
            "\n",
            "Final group distribution (after assignment):\n",
            "group\n",
            "non-severe    56\n",
            "Name: count, dtype: int64\n",
            "Metadata saved to Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pheno['group'] = pheno['title'].apply(\n",
        "    lambda x: 'severe' if 'hemorrhagic fever' in str(x).lower() else 'non-severe'\n",
        ")"
      ],
      "metadata": {
        "id": "y0VD5n0ffo9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# 3️⃣ Preprocessing: Log Transform + Filter Low-Variance Genes\n",
        "# ------------------------------\n",
        "\n",
        "# Log2 transform (microarray data is often already normalized, but we add pseudo-count)\n",
        "expr_log = np.log2(expr + 1)\n",
        "\n",
        "# Filter low-variance genes (keep top 50% variance, like common practice)\n",
        "var_threshold = np.percentile(expr_log.var(axis=0), 50)  # Median variance\n",
        "expr_filtered = expr_log.loc[:, expr_log.var(axis=0) > var_threshold]\n",
        "\n",
        "print(\"Filtered expression shape (genes × samples):\", expr_filtered.shape)\n",
        "\n",
        "# Save filtered data\n",
        "expr_filtered.to_csv('/content/drive/MyDrive/BioResearch/dengue_GSE51808_filtered.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4P5q_6Jmdbfe",
        "outputId": "8a247cd0-27d4-4353-fee6-e18bebad7094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered expression shape (genes × samples): (54715, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# 3️⃣ Minimal Preprocessing (No Plots)\n",
        "# ------------------------------\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Safe log2 transform (GSE51808 is already normalized, but this is safe)\n",
        "expr_log = np.log2(expr + 1)\n",
        "\n",
        "# Basic variance filter (keep genes above median variance - fast)\n",
        "var_threshold = np.percentile(expr_log.var(axis=1), 50)\n",
        "expr_filtered = expr_log[expr_log.var(axis=1) > var_threshold]\n",
        "\n",
        "print(\"Filtered shape (genes × samples):\", expr_filtered.shape)\n",
        "print(f\"Kept {expr_filtered.shape[0]} genes after variance filter.\")\n",
        "\n",
        "# Align samples with groups (ensure index match)\n",
        "common_samples = list(set(expr_filtered.columns) & set(pheno.index))\n",
        "expr_filtered = expr_filtered[common_samples]\n",
        "pheno = pheno.loc[common_samples]\n",
        "\n",
        "print(\"Samples after alignment:\", len(common_samples))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Li5Sr6E2gKkq",
        "outputId": "52d64b5d-7a25-40d3-df55-66bfeffaf099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered shape (genes × samples): (27357, 56)\n",
            "Kept 27357 genes after variance filter.\n",
            "Samples after alignment: 56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# 3️⃣ Preprocessing + Variance Filter (Fixed & Safe – No Plots)\n",
        "# ------------------------------\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Safe log2 transform (handles any zeros/negatives)\n",
        "expr_log = np.log2(expr + 1)\n",
        "print(\"Log2 transform applied.\")\n",
        "\n",
        "# Calculate variance per gene (axis=0 = across samples/columns)\n",
        "gene_variances = expr_log.var(axis=0)  # Series: index = genes (columns of expr_log)\n",
        "\n",
        "# Median threshold\n",
        "var_threshold = np.percentile(gene_variances, 50)\n",
        "print(f\"Median variance threshold: {var_threshold:.4f}\")\n",
        "\n",
        "# Boolean mask aligned with columns (genes)\n",
        "keep_mask = gene_variances > var_threshold\n",
        "\n",
        "# Filter columns using the mask (genes to keep)\n",
        "# This avoids unalignable error by using .loc[:, keep_mask]\n",
        "expr_filtered = expr_log.loc[:, keep_mask]\n",
        "\n",
        "print(\"After variance filter → genes × samples:\", expr_filtered.shape)\n",
        "print(f\"Kept {expr_filtered.shape[0]} genes out of {expr_log.shape[0]}.\")\n",
        "\n",
        "# Transpose for ML (samples as rows, genes as columns)\n",
        "expr_ml = expr_filtered.T\n",
        "\n",
        "# Align samples with pheno (final safety check)\n",
        "common_samples = list(set(expr_ml.index) & set(pheno.index))\n",
        "expr_ml = expr_ml.loc[common_samples]\n",
        "pheno = pheno.loc[common_samples]\n",
        "\n",
        "print(\"\\nSamples after alignment:\", len(common_samples))\n",
        "print(\"Final ML-ready shape (samples × genes):\", expr_ml.shape)\n",
        "\n",
        "# Group check (should be ~46 non-severe, ~10 severe)\n",
        "print(\"\\nGroup distribution:\")\n",
        "print(pheno['group'].value_counts())\n",
        "\n",
        "# Save ready data\n",
        "expr_ml.to_csv('/content/drive/MyDrive/BioResearch/dengue_ml_ready.csv')\n",
        "print(\"ML-ready data saved to Drive.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY7bcsqvgliR",
        "outputId": "ed4ec673-e1b2-4fb9-eb90-39e0ef669f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log2 transform applied.\n",
            "Median variance threshold: 0.2480\n",
            "After variance filter → genes × samples: (54715, 28)\n",
            "Kept 54715 genes out of 54715.\n",
            "\n",
            "Samples after alignment: 28\n",
            "Final ML-ready shape (samples × genes): (28, 54715)\n",
            "\n",
            "Group distribution:\n",
            "group\n",
            "non-severe    20\n",
            "severe         8\n",
            "Name: count, dtype: int64\n",
            "ML-ready data saved to Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# 5️⃣ ML Models – Robust Version (Paper’s 6 Models + XGBoost – Stratified 5-Fold CV)\n",
        "# ------------------------------\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Use top genes by variance (adjust top_n for speed/accuracy)\n",
        "top_n = 2000  # 2000 is fast; try 5000 or 10000 later\n",
        "gene_vars = expr_ml.var(axis=0)\n",
        "top_genes = gene_vars.nlargest(top_n).index.tolist()\n",
        "\n",
        "X = expr_ml[top_genes].values  # numpy for consistency\n",
        "y = pheno['group'].map({'non-severe': 0, 'severe': 1}).values\n",
        "\n",
        "print(f\"Training with {X.shape[1]} genes | Samples: {X.shape[0]} | Classes: {np.bincount(y)}\")\n",
        "\n",
        "# Stratified 5-fold CV (better than single split for small/imbalanced data)\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "models = {\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'AdaBoost': AdaBoostClassifier(n_estimators=50, random_state=42),\n",
        "    'SVM': SVC(probability=True, random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'XGBoost': XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss')\n",
        "}\n",
        "\n",
        "results = {name: {'acc': [], 'prec': [], 'rec': [], 'auc': []} for name in models}\n",
        "\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "    for name, model in models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Safe probability extraction (some models return shape (n,1) or (n,))\n",
        "        if hasattr(model, 'predict_proba'):\n",
        "            y_prob = model.predict_proba(X_test)\n",
        "            if y_prob.ndim == 2 and y_prob.shape[1] == 2:\n",
        "                y_prob = y_prob[:, 1]  # probability of class 1 (severe)\n",
        "            else:\n",
        "                y_prob = y_prob.flatten()  # fallback\n",
        "        else:\n",
        "            y_prob = y_pred.astype(float)  # fallback to binary\n",
        "\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "        rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "        auc = roc_auc_score(y_test, y_prob) if len(np.unique(y_test)) > 1 else np.nan\n",
        "\n",
        "        results[name]['acc'].append(acc)\n",
        "        results[name]['prec'].append(prec)\n",
        "        results[name]['rec'].append(rec)\n",
        "        results[name]['auc'].append(auc)\n",
        "\n",
        "# Average performance\n",
        "results_df = pd.DataFrame({\n",
        "    name: {\n",
        "        'Accuracy': np.mean(res['acc']),\n",
        "        'Precision': np.mean(res['prec']),\n",
        "        'Recall (Sensitivity)': np.mean(res['rec']),\n",
        "        'AUC': np.nanmean(res['auc'])  # nanmean ignores N/A\n",
        "    } for name, res in results.items()\n",
        "}).T\n",
        "\n",
        "print(\"\\nML Model Performance (5-Fold Stratified CV – Average):\")\n",
        "print(results_df.round(4))\n",
        "\n",
        "# Best model\n",
        "best_auc = results_df['AUC'].idxmax() if results_df['AUC'].notna().any() else 'N/A'\n",
        "best_acc = results_df['Accuracy'].idxmax()\n",
        "print(f\"\\nBest model by AUC: {best_auc}\")\n",
        "print(f\"Best model by Accuracy: {best_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-4v07ayjjOQ",
        "outputId": "bc7261e1-9468-4623-9bbb-0dfbccc8d7f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with 2000 genes | Samples: 28 | Classes: [20  8]\n",
            "\n",
            "ML Model Performance (5-Fold Stratified CV – Average):\n",
            "               Accuracy  Precision  Recall (Sensitivity)     AUC\n",
            "KNN              0.8600     0.7667                   0.9  0.8875\n",
            "Naive Bayes      0.8933     0.8333                   0.9  0.9000\n",
            "AdaBoost         0.8267     0.7667                   0.8  0.8250\n",
            "SVM              0.7933     0.6000                   0.6  0.9250\n",
            "Random Forest    0.9000     0.7333                   0.8  0.9500\n",
            "XGBoost          0.8600     0.8333                   0.8  0.9000\n",
            "\n",
            "Best model by AUC: Random Forest\n",
            "Best model by Accuracy: Random Forest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "from imblearn.over_sampling import SMOTE  # For imbalance\n",
        "import shap  # For biomarker prediction (explainability)\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Load your dengue data (from previous saved file or GEO)\n",
        "# If you have 'dengue_ml_ready.csv' from earlier\n",
        "expr_ml = pd.read_csv('/content/drive/MyDrive/BioResearch/dengue_ml_ready.csv', index_col=0)  # samples × genes\n",
        "\n",
        "# If not, load from GEO (uncomment if needed)\n",
        "# import GEOparse\n",
        "# gse = GEOparse.get_GEO(geo='GSE51808', destdir=\"./\")\n",
        "# expr = gse.pivot_samples('VALUE')\n",
        "# expr_log = np.log2(expr + 1)\n",
        "# expr_ml = expr_log.T  # samples × genes\n",
        "\n",
        "# Pheno (groups) – assume you have it; if not, recreate\n",
        "pheno = pd.read_csv('/content/drive/MyDrive/BioResearch/dengue_GSE51808_metadata_fixed.csv', index_col=0)\n",
        "y = pheno['group'].map({'non-severe': 0, 'severe': 1})\n",
        "\n",
        "print(\"Data shape (samples × genes):\", expr_ml.shape)\n",
        "print(\"Labels distribution:\", y.value_counts().to_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lx4DoeWQlvOl",
        "outputId": "3c5b2215-38aa-411a-d9be-ecabf5badf71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Data shape (samples × genes): (28, 54715)\n",
            "Labels distribution: {0: 46, 1: 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# 3️⃣ Preprocessing + Variance Filter (Fixed & Robust – No Plots)\n",
        "# ------------------------------\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Safe log2 transform\n",
        "expr_log = np.log2(expr + 1)\n",
        "print(\"Log2 transform applied.\")\n",
        "\n",
        "# Calculate variance per gene (axis=0 = across samples/columns)\n",
        "gene_variances = expr_log.var(axis=0)  # Series with gene names as index\n",
        "\n",
        "# Median threshold\n",
        "var_threshold = np.percentile(gene_variances, 50)\n",
        "print(f\"Median variance threshold: {var_threshold:.4f}\")\n",
        "\n",
        "# Create boolean mask using the exact column index (genes)\n",
        "# This ensures perfect alignment\n",
        "keep_mask = pd.Series(False, index=expr_log.columns)\n",
        "keep_mask[gene_variances.index] = gene_variances > var_threshold\n",
        "\n",
        "# Filter using .loc on columns\n",
        "expr_filtered = expr_log.loc[:, keep_mask]\n",
        "\n",
        "print(\"After variance filter → genes × samples:\", expr_filtered.shape)\n",
        "print(f\"Kept {expr_filtered.shape[0]} genes out of {expr_log.shape[0]}.\")\n",
        "\n",
        "# Transpose for ML (samples as rows, genes as columns)\n",
        "expr_ml = expr_filtered.T\n",
        "\n",
        "# Align samples with pheno (final safety check)\n",
        "common_samples = list(set(expr_ml.index) & set(pheno.index))\n",
        "expr_ml = expr_ml.loc[common_samples]\n",
        "pheno = pheno.loc[common_samples]\n",
        "\n",
        "print(\"\\nSamples after alignment:\", len(common_samples))\n",
        "print(\"Final ML-ready shape (samples × genes):\", expr_ml.shape)\n",
        "\n",
        "# Group check (should show non-severe ~20, severe ~8)\n",
        "print(\"\\nGroup distribution:\")\n",
        "print(pheno['group'].value_counts())\n",
        "\n",
        "# Save ready data\n",
        "expr_ml.to_csv('/content/drive/MyDrive/BioResearch/dengue_ml_ready.csv')\n",
        "print(\"ML-ready data saved to Drive.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFTkhyPsmEnn",
        "outputId": "337ad45b-480c-4a82-96a4-346159230023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log2 transform applied.\n",
            "Median variance threshold: 0.2480\n",
            "After variance filter → genes × samples: (54715, 28)\n",
            "Kept 54715 genes out of 54715.\n",
            "\n",
            "Samples after alignment: 28\n",
            "Final ML-ready shape (samples × genes): (28, 54715)\n",
            "\n",
            "Group distribution:\n",
            "group\n",
            "non-severe    20\n",
            "severe         8\n",
            "Name: count, dtype: int64\n",
            "ML-ready data saved to Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# Cell: Build & Train Custom DNN Model for Dengue Severity\n",
        "# ------------------------------\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE  # Handle imbalance\n",
        "import shap  # For biomarker discovery\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Use all genes or subsample for speed (change top_n if needed)\n",
        "top_n = 5000  # 5000 is good balance; increase to 10000+ for more power\n",
        "gene_vars = expr_ml.var(axis=0)\n",
        "top_genes = gene_vars.nlargest(top_n).index.tolist()\n",
        "\n",
        "X = expr_ml[top_genes].values  # numpy array\n",
        "y = pheno['group'].map({'non-severe': 0, 'severe': 1}).values\n",
        "\n",
        "print(f\"Using {X.shape[1]} genes | Samples: {X.shape[0]} | Classes: {np.bincount(y)}\")\n",
        "\n",
        "# Normalize features (important for DNN)\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Handle imbalance with SMOTE (oversample severe class)\n",
        "smote = SMOTE(random_state=42)\n",
        "X_res, y_res = smote.fit_resample(X, y)\n",
        "print(\"After SMOTE:\", X_res.shape, np.bincount(y_res))\n",
        "\n",
        "# Split (80/20 stratified)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, stratify=y_res, random_state=42)\n",
        "\n",
        "# Custom DNN architecture (3 hidden layers + dropout for regularization)\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_dim=X_train.shape[1], activation='relu'))  # Input layer\n",
        "model.add(Dropout(0.3))  # Prevent overfitting\n",
        "model.add(Dense(128, activation='relu'))  # Hidden layer 1\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu'))  # Hidden layer 2\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output (binary: 0/1)\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping to avoid overfitting\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train (10–50 epochs, class weights if needed)\n",
        "class_weights = {0: 1.0, 1: len(y_res[y_res==0]) / len(y_res[y_res==1])} if len(np.unique(y_res)) > 1 else None\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    validation_split=0.2,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate on test set\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "y_prob = model.predict(X_test).flatten()\n",
        "y_pred = (y_prob > 0.5).astype(int)\n",
        "\n",
        "prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "print(\"\\nCustom DNN Performance on Test Set:\")\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall (Sensitivity): {rec:.4f}\")\n",
        "print(f\"AUC: {auc:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Non-Severe', 'Severe']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lumg_HofmYHB",
        "outputId": "5af61cfa-a748-4e85-fb98-eaed6f1af4f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 5000 genes | Samples: 28 | Classes: [20  8]\n",
            "After SMOTE: (40, 5000) [20 20]\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3s/step - accuracy: 0.5933 - loss: 0.7957 - val_accuracy: 0.8571 - val_loss: 0.6334\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.8517 - loss: 0.5891 - val_accuracy: 0.8571 - val_loss: 0.3548\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.8992 - loss: 0.4333 - val_accuracy: 0.8571 - val_loss: 0.1349\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.9525 - loss: 0.6743 - val_accuracy: 1.0000 - val_loss: 0.0340\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.8517 - loss: 0.6314 - val_accuracy: 1.0000 - val_loss: 0.0201\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8571 - val_loss: 0.1310\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.8571 - val_loss: 0.3729\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9525 - loss: 0.1312 - val_accuracy: 0.8571 - val_loss: 0.5163\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9525 - loss: 0.0744 - val_accuracy: 0.8571 - val_loss: 0.6328\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.8783 - loss: 0.6475 - val_accuracy: 0.8571 - val_loss: 0.5685\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 1.1175e-04 - val_accuracy: 0.8571 - val_loss: 0.5009\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9733 - loss: 0.4921 - val_accuracy: 0.8571 - val_loss: 0.2941\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9733 - loss: 0.0479 - val_accuracy: 1.0000 - val_loss: 0.0449\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9733 - loss: 0.3406 - val_accuracy: 1.0000 - val_loss: 9.6617e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9525 - loss: 0.7286 - val_accuracy: 1.0000 - val_loss: 9.7364e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.0254e-04 - val_accuracy: 1.0000 - val_loss: 6.0799e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9525 - loss: 0.0382 - val_accuracy: 1.0000 - val_loss: 4.5224e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9200 - loss: 0.6081 - val_accuracy: 1.0000 - val_loss: 4.3954e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 1.2905e-05 - val_accuracy: 1.0000 - val_loss: 0.0067\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 1.1540e-04 - val_accuracy: 0.8571 - val_loss: 0.1910\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9525 - loss: 0.1598 - val_accuracy: 0.8571 - val_loss: 0.7558\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9050 - loss: 0.2755 - val_accuracy: 0.8571 - val_loss: 0.6979\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.8571 - val_loss: 0.5936\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 2.7620e-05 - val_accuracy: 0.8571 - val_loss: 0.5136\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 4.5190e-04 - val_accuracy: 0.8571 - val_loss: 0.4548\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9525 - loss: 0.0449 - val_accuracy: 0.8571 - val_loss: 0.3144\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9525 - loss: 0.2854 - val_accuracy: 1.0000 - val_loss: 0.0544\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 3.2166e-04 - val_accuracy: 1.0000 - val_loss: 0.0064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ef518388180> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step\n",
            "\n",
            "Custom DNN Performance on Test Set:\n",
            "Accuracy: 0.8750\n",
            "Precision: 1.0000\n",
            "Recall (Sensitivity): 0.7500\n",
            "AUC: 0.8750\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Non-Severe       0.80      1.00      0.89         4\n",
            "      Severe       1.00      0.75      0.86         4\n",
            "\n",
            "    accuracy                           0.88         8\n",
            "   macro avg       0.90      0.88      0.87         8\n",
            "weighted avg       0.90      0.88      0.87         8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# 6️⃣ Predict Novel Biomarkers with SHAP (on Best Model: Random Forest)\n",
        "# ------------------------------\n",
        "\n",
        "import shap\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Use the trained Random Forest model\n",
        "best_model = models['Random Forest']\n",
        "\n",
        "print(\"Number of genes used:\", len(top_genes))\n",
        "\n",
        "# Convert to DataFrame (SHAP prefers feature names)\n",
        "X_test_used = pd.DataFrame(X_test, columns=top_genes)\n",
        "\n",
        "print(\"Computing SHAP values on test set...\")\n",
        "\n",
        "# TreeExplainer (best for Random Forest)\n",
        "explainer = shap.TreeExplainer(best_model)\n",
        "\n",
        "shap_values = explainer.shap_values(X_test_used)\n",
        "\n",
        "# ------------------------------\n",
        "# 🔥 Handle all possible SHAP formats safely\n",
        "# ------------------------------\n",
        "\n",
        "# Case 1️⃣: Old versions → list of arrays [class0, class1]\n",
        "if isinstance(shap_values, list):\n",
        "    shap_positive = shap_values[1]   # class 1 (severe dengue)\n",
        "\n",
        "# Case 2️⃣: New versions → 3D array (n_samples, n_features, n_classes)\n",
        "elif isinstance(shap_values, np.ndarray) and shap_values.ndim == 3:\n",
        "    shap_positive = shap_values[:, :, 1]  # select class 1\n",
        "\n",
        "# Case 3️⃣: Already 2D (n_samples, n_features)\n",
        "else:\n",
        "    shap_positive = shap_values\n",
        "\n",
        "print(\"SHAP values shape (positive class):\", shap_positive.shape)\n",
        "\n",
        "# ------------------------------\n",
        "# Compute Mean |SHAP| per gene\n",
        "# ------------------------------\n",
        "\n",
        "shap_abs_mean = np.abs(shap_positive).mean(axis=0)\n",
        "\n",
        "print(\"Length of top_genes:\", len(top_genes))\n",
        "print(\"Length of SHAP mean:\", len(shap_abs_mean))\n",
        "\n",
        "# ------------------------------\n",
        "# Build Importance DataFrame\n",
        "# ------------------------------\n",
        "\n",
        "shap_importance = pd.DataFrame({\n",
        "    'gene': top_genes,\n",
        "    'shap_mean_abs': shap_abs_mean\n",
        "})\n",
        "\n",
        "shap_importance = shap_importance.sort_values(\n",
        "    'shap_mean_abs',\n",
        "    ascending=False\n",
        ").reset_index(drop=True)\n",
        "\n",
        "print(\"\\nTop 20 Novel Biomarker Candidates (by SHAP importance for severe dengue prediction):\")\n",
        "display(shap_importance.head(20))\n",
        "\n",
        "# ------------------------------\n",
        "# Save Top 100\n",
        "# ------------------------------\n",
        "\n",
        "shap_importance.head(100).to_csv(\n",
        "    '/content/drive/MyDrive/BioResearch/dengue_novel_biomarkers_SHAP_RF.csv',\n",
        "    index=False\n",
        ")\n",
        "\n",
        "print(\"Top 100 SHAP-based biomarkers saved to Drive.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "id": "2d3tLxx7tlm-",
        "outputId": "7f9bbc0d-c13c-4fe3-b4fa-afb9cf7b1b7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of genes used: 5000\n",
            "Computing SHAP values on test set...\n",
            "SHAP values shape (positive class): (8, 5000)\n",
            "Length of top_genes: 5000\n",
            "Length of SHAP mean: 5000\n",
            "\n",
            "Top 20 Novel Biomarker Candidates (by SHAP importance for severe dengue prediction):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "              gene  shap_mean_abs\n",
              "0     233011_PM_at       0.020000\n",
              "1   205114_PM_s_at       0.009557\n",
              "2   210549_PM_s_at       0.008880\n",
              "3     240182_PM_at       0.008650\n",
              "4     217518_PM_at       0.008385\n",
              "5     227671_PM_at       0.008261\n",
              "6     232397_PM_at       0.008261\n",
              "7   202587_PM_s_at       0.008261\n",
              "8     212845_PM_at       0.007826\n",
              "9     226817_PM_at       0.007826\n",
              "10    232883_PM_at       0.007469\n",
              "11    235916_PM_at       0.007391\n",
              "12    238149_PM_at       0.007391\n",
              "13    210029_PM_at       0.007391\n",
              "14    244358_PM_at       0.007391\n",
              "15    235805_PM_at       0.007228\n",
              "16  224342_PM_x_at       0.007201\n",
              "17    206637_PM_at       0.006957\n",
              "18  211821_PM_x_at       0.006957\n",
              "19  211641_PM_x_at       0.006522"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c460fb10-d46b-4c29-950c-5348dc25b01b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gene</th>\n",
              "      <th>shap_mean_abs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>233011_PM_at</td>\n",
              "      <td>0.020000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>205114_PM_s_at</td>\n",
              "      <td>0.009557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>210549_PM_s_at</td>\n",
              "      <td>0.008880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>240182_PM_at</td>\n",
              "      <td>0.008650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>217518_PM_at</td>\n",
              "      <td>0.008385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>227671_PM_at</td>\n",
              "      <td>0.008261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>232397_PM_at</td>\n",
              "      <td>0.008261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>202587_PM_s_at</td>\n",
              "      <td>0.008261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>212845_PM_at</td>\n",
              "      <td>0.007826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>226817_PM_at</td>\n",
              "      <td>0.007826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>232883_PM_at</td>\n",
              "      <td>0.007469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>235916_PM_at</td>\n",
              "      <td>0.007391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>238149_PM_at</td>\n",
              "      <td>0.007391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>210029_PM_at</td>\n",
              "      <td>0.007391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>244358_PM_at</td>\n",
              "      <td>0.007391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>235805_PM_at</td>\n",
              "      <td>0.007228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>224342_PM_x_at</td>\n",
              "      <td>0.007201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>206637_PM_at</td>\n",
              "      <td>0.006957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>211821_PM_x_at</td>\n",
              "      <td>0.006957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>211641_PM_x_at</td>\n",
              "      <td>0.006522</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c460fb10-d46b-4c29-950c-5348dc25b01b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c460fb10-d46b-4c29-950c-5348dc25b01b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c460fb10-d46b-4c29-950c-5348dc25b01b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"Top 100 SHAP-based biomarkers saved to Drive\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"gene\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"233011_PM_at\",\n          \"206637_PM_at\",\n          \"235805_PM_at\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shap_mean_abs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.002831684836175568,\n        \"min\": 0.006521739130434785,\n        \"max\": 0.02,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.006956521739130436,\n          0.007228260869565217,\n          0.02\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 100 SHAP-based biomarkers saved to Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# ML Models – Direct Jump (Paper’s 6 Models + XGBoost – 5-Fold CV)\n",
        "# ------------------------------\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Select top genes by variance (fast & sufficient for n=28)\n",
        "top_n = 2000  # Change to 5000 or expr_ml.shape[1] for more power\n",
        "gene_vars = expr_ml.var(axis=0)\n",
        "top_genes = gene_vars.nlargest(top_n).index.tolist()\n",
        "\n",
        "X = expr_ml[top_genes].values  # numpy array for speed\n",
        "y = pheno['group'].map({'non-severe': 0, 'severe': 1}).values\n",
        "\n",
        "print(f\"Training with {X.shape[1]} genes | Samples: {X.shape[0]} | Classes: {np.bincount(y)}\")\n",
        "\n",
        "# Stratified 5-fold CV (more reliable than single split)\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "models = {\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'AdaBoost': AdaBoostClassifier(n_estimators=50, random_state=42),\n",
        "    'SVM': SVC(probability=True, random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'XGBoost': XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss')\n",
        "}\n",
        "\n",
        "results = {name: {'acc': [], 'prec': [], 'rec': [], 'auc': []} for name in models}\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(skf.split(X, y), 1):\n",
        "    print(f\"\\nFold {fold}/5\")\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "    for name, model in models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Safe probability extraction\n",
        "        if hasattr(model, 'predict_proba'):\n",
        "            y_prob = model.predict_proba(X_test)\n",
        "            if y_prob.ndim == 2 and y_prob.shape[1] == 2:\n",
        "                y_prob = y_prob[:, 1]  # prob of class 1 (severe)\n",
        "            else:\n",
        "                y_prob = y_prob.flatten()  # fallback\n",
        "        else:\n",
        "            y_prob = y_pred.astype(float)\n",
        "\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "        rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "        auc = roc_auc_score(y_test, y_prob) if len(np.unique(y_test)) > 1 else np.nan\n",
        "\n",
        "        results[name]['acc'].append(acc)\n",
        "        results[name]['prec'].append(prec)\n",
        "        results[name]['rec'].append(rec)\n",
        "        results[name]['auc'].append(auc)\n",
        "\n",
        "# Average performance across folds\n",
        "results_df = pd.DataFrame({\n",
        "    name: {\n",
        "        'Accuracy': np.mean(res['acc']),\n",
        "        'Precision': np.mean(res['prec']),\n",
        "        'Recall (Sensitivity)': np.mean(res['rec']),\n",
        "        'AUC': np.nanmean(res['auc'])\n",
        "    } for name, res in results.items()\n",
        "}).T\n",
        "\n",
        "print(\"\\nML Model Performance (5-Fold Stratified CV – Average):\")\n",
        "print(results_df.round(4))\n",
        "\n",
        "# Best model\n",
        "best_auc = results_df['AUC'].idxmax() if results_df['AUC'].notna().any() else 'N/A'\n",
        "best_acc = results_df['Accuracy'].idxmax()\n",
        "print(f\"\\nBest model by AUC: {best_auc}\")\n",
        "print(f\"Best model by Accuracy: {best_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjrWTovBnp6T",
        "outputId": "d4517af0-a665-45cd-e545-b2e7e6c2c677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with 2000 genes | Samples: 28 | Classes: [20  8]\n",
            "\n",
            "Fold 1/5\n",
            "\n",
            "Fold 2/5\n",
            "\n",
            "Fold 3/5\n",
            "\n",
            "Fold 4/5\n",
            "\n",
            "Fold 5/5\n",
            "\n",
            "ML Model Performance (5-Fold Stratified CV – Average):\n",
            "               Accuracy  Precision  Recall (Sensitivity)     AUC\n",
            "KNN              0.8600     0.7667                   0.9  0.8875\n",
            "Naive Bayes      0.8933     0.8333                   0.9  0.9000\n",
            "AdaBoost         0.8267     0.7667                   0.8  0.8250\n",
            "SVM              0.7933     0.6000                   0.6  0.9250\n",
            "Random Forest    0.9000     0.7333                   0.8  0.9500\n",
            "XGBoost          0.8600     0.8333                   0.8  0.9000\n",
            "\n",
            "Best model by AUC: Random Forest\n",
            "Best model by Accuracy: Random Forest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# 6️⃣ Predict Novel Biomarkers with SHAP (on Best Model: Random Forest)\n",
        "# ------------------------------\n",
        "\n",
        "import shap\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Use the trained Random Forest model (best by AUC from your output)\n",
        "best_model = models['Random Forest']\n",
        "\n",
        "# Features used (top_genes from previous cell)\n",
        "print(\"Number of genes used:\", len(top_genes))\n",
        "\n",
        "# Prepare X_test_used as DataFrame with gene names (SHAP likes feature names)\n",
        "X_test_used = pd.DataFrame(X_test, columns=top_genes)\n",
        "\n",
        "print(\"Computing SHAP values on test set... (should be fast for RF, 30s–2min)\")\n",
        "\n",
        "# TreeExplainer for Random Forest (fast & accurate)\n",
        "explainer = shap.TreeExplainer(best_model)\n",
        "\n",
        "# Compute SHAP values (returns list for multi-class, but binary often [neg, pos])\n",
        "shap_values = explainer.shap_values(X_test_used)\n",
        "\n",
        "# Handle binary case safely\n",
        "if isinstance(shap_values, list):\n",
        "    # Take SHAP for positive class (severe = 1)\n",
        "    shap_positive = shap_values[1]  # shape: (n_test, n_features)\n",
        "else:\n",
        "    shap_positive = shap_values  # if already array for positive class\n",
        "\n",
        "print(\"SHAP values shape:\", shap_positive.shape)\n",
        "\n",
        "# Average absolute SHAP per gene (importance score)\n",
        "shap_abs_mean = np.abs(shap_positive).mean(axis=0)  # length = n_features\n",
        "\n",
        "# Confirm lengths match\n",
        "print(\"Length of top_genes:\", len(top_genes))\n",
        "print(\"Length of SHAP mean:\", len(shap_abs_mean))\n",
        "\n",
        "# Build DataFrame (lengths must match now)\n",
        "shap_importance = pd.DataFrame({\n",
        "    'gene': top_genes,\n",
        "    'shap_mean_abs': shap_abs_mean\n",
        "}).sort_values('shap_mean_abs', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"\\nTop 20 Novel Biomarker Candidates (by SHAP importance for severe dengue prediction):\")\n",
        "display(shap_importance.head(20))\n",
        "\n",
        "# Save top 100 candidates\n",
        "shap_importance.head(100).to_csv(\n",
        "    '/content/drive/MyDrive/BioResearch/dengue_novel_biomarkers_SHAP_RF.csv',\n",
        "    index=False\n",
        ")\n",
        "print(\"Top 100 SHAP-based biomarkers saved to Drive.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "6AQDEC7nrbS-",
        "outputId": "62939874-1c8d-498c-cf2d-8ccd2f3d5bb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of genes used: 5000\n",
            "Computing SHAP values on test set... (should be fast for RF, 30s–2min)\n",
            "SHAP values shape: (8, 5000, 2)\n",
            "Length of top_genes: 5000\n",
            "Length of SHAP mean: 5000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Per-column arrays must each be 1-dimensional",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-581/1614082385.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Build DataFrame (lengths must match now)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m shap_importance = pd.DataFrame({\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;34m'gene'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtop_genes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;34m'shap_mean_abs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mshap_abs_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0mraw_lengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Per-column arrays must each be 1-dimensional\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraw_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Per-column arrays must each be 1-dimensional"
          ]
        }
      ]
    }
  ]
}